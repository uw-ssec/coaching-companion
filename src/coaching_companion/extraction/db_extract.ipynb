{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ibis-framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import ibis\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the following tables\n",
    "required_tables = ['vce_components_meta']\n",
    "attr_datatypes = ['vce_datatype_lookup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaml file path\n",
    "yaml_file_name = 'cc_db_info.yml'\n",
    "yaml_file_path = os.path.join(os.getcwd(), yaml_file_name)\n",
    "\n",
    "print(f\"Yaml file path: {yaml_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Dictionaries\n",
    "\n",
    "attr_dict = {} # Attribute dictionary (becomes a dict of dicts)\n",
    "datatype_dict = {} # Data type dictionary (becomes a list of dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Access Data in the Database\n",
    "## Connection Functions\n",
    "### Establish the connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Connection to the Development Database\n",
    "def gen_connection():\n",
    "    conn = ibis.postgres.connect(\n",
    "        host=os.environ['POSTGRES_DB_HOST'],\n",
    "        user=os.environ['POSTGRES_DB_USER'],\n",
    "        password=os.environ['POSTGRES_DB_PASSWORD'],\n",
    "        database=os.environ['POSTGRES_DB_NAME']\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Functions\n",
    "### Access the Table Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Table\n",
    "def get_table(table_name, conn = gen_connection()):\n",
    "    return conn.table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the Table Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Table Columns\n",
    "def get_table_columns(table_name, conn = gen_connection()) -> List[str]:\n",
    "    table = get_table(table_name, conn)\n",
    "    return table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Table Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Tables\n",
    "def list_tables(conn = gen_connection()) -> List[str]:\n",
    "    return conn.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Classes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Classes\n",
    "def extract_classes(conn_table,column:str = 'meta_value') -> List[str]:\n",
    "    # Used when joining the same table\n",
    "    a = conn_table.alias('a') # Add alias for table a\n",
    "    b = conn_table.alias('b') # Add alias for table b\n",
    "\n",
    "    # Perform the join with conditions\n",
    "    joined = a.join(b, [a.component_id == b.component_id,\n",
    "                        b.meta_key == 'type',\n",
    "                        ~a.meta_key.like('lms_assignment_id%')])\n",
    "    query = joined[b.meta_value].distinct()\n",
    "    result = query.execute()\n",
    "    \n",
    "    return result[column].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Attributes and Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attr_datatypes(conn_table1,conn_table2,attr:str) -> pd.DataFrame:\n",
    "    # Aliases for readability\n",
    "    a = conn_table1.alias('a')\n",
    "    b = conn_table1.alias('b')\n",
    "    c = conn_table1.alias('c')\n",
    "    d = conn_table2.alias('d')\n",
    "\n",
    "    joined = a.join(b, a.component_id == b.component_id) \\\n",
    "                .join(d, b.meta_key == d.type) \\\n",
    "                .join(c, [a.component_id == c.component_id,\n",
    "                            c.meta_key == 'type',\n",
    "                            c.meta_value == attr,\n",
    "                            ~a.meta_key.like('lms_assignment_id%')])\n",
    "\n",
    "    query = joined[[b.meta_key, d.datatype]].distinct()\n",
    "    result = query.execute()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Functions\n",
    "### Generate List of Datatype Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts(input_dataframe: pd.DataFrame, column_name_key: str, column_name_value: str) -> List[Dict[str, str]]:\n",
    "    list_of_datatypes = [{row[column_name_key]: row[column_name_value]} for index, row in input_dataframe.iterrows()]\n",
    "    return list_of_datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dictionary Hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict(new_dict: Dict, value_dict: Dict, key) -> Dict:\n",
    "    new_dict[key] = value_dict\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yaml Functions\n",
    "### Create/Load the YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yaml(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Database Class Data and Move to Yaml File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Connection to the Development Database\n",
    "try:\n",
    "    conn = gen_connection()\n",
    "    print(\"Connection to the database established.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the required tables exist in the database\n",
    "tables = list_tables(conn)\n",
    "\n",
    "if set(required_tables).issubset(set(tables)):\n",
    "    print(f\"All required tables found in the database.\")\n",
    "else:\n",
    "    print(f\"Table {required_tables} not found in the database.\")\n",
    "\n",
    "if set(attr_datatypes).issubset(set(tables)):\n",
    "    print(f\"All attribute/datatype tables found in the database.\")\n",
    "else:\n",
    "    print(f\"Table {attr_datatypes} not found in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the required tables within the database and extract the necessary information\n",
    "for i in range(len(required_tables)):\n",
    "\n",
    "    # Initialize the dictionaries\n",
    "    table_dict = {} # Table dictionary (becomes a dict of dicts)\n",
    "\n",
    "    # Loop over the required tables\n",
    "    vce_components_meta = get_table(required_tables[i],conn)\n",
    "    if len(attr_datatypes) == 1:\n",
    "        vce_datatype_lookup = get_table(attr_datatypes[0],conn)\n",
    "    else:\n",
    "        vce_datatype_lookup = get_table(attr_datatypes[i],conn)\n",
    "\n",
    "    # Initialize the dictionaries\n",
    "    class_dict = {} # Class dictionary (becomes a dict of dicts)\n",
    "    # Extract the classes\n",
    "    classes = extract_classes(vce_components_meta)\n",
    "\n",
    "    # Loop over the classes\n",
    "    for j in range(len(classes)):\n",
    "        # # Initialize the dictionaries\n",
    "        attr_dict = {} # Attribute dictionary (becomes a dict of dicts)\n",
    "        # datatype_dict = {} # Data type dictionary (becomes a list of dicts)\n",
    "\n",
    "        # Extract the attributes and datatypes\n",
    "        attr_datatypes = extract_attr_datatypes(vce_components_meta,vce_datatype_lookup,classes[j])\n",
    "        \n",
    "        # Loop over the attributes\n",
    "        for k in range(len(attr_datatypes)):\n",
    "            # Generate the list of dictionaries\n",
    "            datatype_dict = list_of_dicts(attr_datatypes,'meta_key','datatype')\n",
    "            \n",
    "        # Generate the nested dictionary\n",
    "        class_dict = nested_dict(class_dict,datatype_dict,classes[j])\n",
    "        print(f\"Class dictionary added the {classes[j]} class contents\")\n",
    "\n",
    "    # Create the new table in the dictionary\n",
    "    table_dict = nested_dict(table_dict,class_dict,required_tables[i])\n",
    "    print(f\"Table dictionary added the {required_tables[i]} table contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify contents of the table dictionary\n",
    "print(\"The table dictionary is as follows:\")\n",
    "print(yaml.dump(table_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary to a yaml file\n",
    "write_yaml(yaml_file_path,table_dict)\n",
    "print(f\"Yaml file written to {yaml_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
